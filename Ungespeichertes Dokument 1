Für Sequenzverarbeitung mit unterschiedlicher EIngabelänge: 
Zur Bearbeitung solcher Daten haben sich daher rekurrente Netzwerke bewährt, die den Kontext voriger Eingabedaten in ihrem „Kurzzeitgedächtnis“ speichern können (Callan (2003, S. 119).

Den grundsätzlichen Beweis dass CNNs auch für Textklassifikationen eingesetzt werden können, erbrachte Yoon Kim in Convolutional Neural Networks for Sentence Classification erst im Jahre 2014 (Kim (2014). Er nutzte vortrainierte Word2Vec-Vektoren um Sätze zu klassifizieren und verschiedene Kernel-Größen um unterschiedlich große Features finden zu können. Diese werden dann einen voll verbundenen Softmax-Layer weitergegeben. Ein einfaches, einschichtiges CNN lieferte dem Autor nach „überraschend gute Ergebnisse“. Je nach Datenset erreichte es eine korrekte Klassifizierungs-Rate von bis zu 89 %.

Sutskever, Vinyals, and Le (2014): LSTMs (im Gegensatz zu deep neural networks) hingegen nehmen jede mögliche Eingabe mit beliebiger Dimension und bilden diese zur Weiterverarbeitung auf einen Vektor mit fixer Größe ab.
Modell der Autoren bestand aus zwei LSTMs. Vorteil:  Anzahl der Parameter im Modell können erhöht werden, was zu einer besseren Performance führt, ohne die Leistungsanforderungen allzu sehr zu steigern. Sie wählten ein LSTM mit vier Schichten zu je 1000 Zellen. Die genutzten Word-Embeddings hatten 1000 Dimensionen. Besonderheit:Reihenfolge der Eingabesequenz war vertauscht. Statt die Tokens also in der Reihenfolge „a - b - c“ zu lesen, arbeitete das Modell mit „c - b - a“. Die Autoren schrieben, diese einfache Änderung habe einen vorteilhaften Einfluss auf die Leistung des Systems gehabt, ohne den Effekt genau erklären zu können.

Für die meisten Anwendungen trifft man die Annahme, dass ein Satz nur eine Meinung ausdrückt (Liu (2012, S. 37). (ich nehme an, dass ein satz nur eine emotione hat, stimmt zwar nicht immer, macht arbeiten aber einfacher) 

Dan Jurafsky and James H. Martin (??, S. 392): Eine sehr einfache Methode zur Sentiment-Analyse ist das Berechnen des Verhältnisses von positiv und negativ annotierten Wörtern aus einem Sentiment-Lexikon. Gibt es mehr positive als negative Wörter, wird auch das Sentiment des Dokumentes als positiv angenommen (das mache ich auch mit den emotionen-lexika)

Liu (2012, S. 25): Features für die sentiment analysis: Anzahl des Auftretens bestimmter Wörter oder n-Gramme, Anzahl des Auftretens bestimmter Wörter oder n-Gramme, • Das Auftreten von Sentiment-Wörtern und -Phrasen, Wörteranzahl im Dokument, ob ! enthalten ist, anzahl der wörter aus lexikon, 

features für affekt-analyse: 
Ebba Cecilia Ovesdotter Alm (2002, S. 33 f.): wörter die einen affekt direkt beschreiben (anger“, „angry“, „fearful“, „delight)
Ebba Cecilia Ovesdotter Alm (2002, S. 50 f.): besondere interpunktion (!?, !!, ...)


Yin et al. (2017): Das RNN ist gut dafür ausgestattet auch über längere Distanzen Relationen zwischen verschiedenen Wörtern oder Satzteilen zu finden (brauche ich denke nicht). ...GRU und das CNN ähnlich exakt arbeiten, wenn die Satzlänge relativ klein ist.

